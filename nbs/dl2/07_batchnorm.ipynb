{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_06 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the data and training interface from where we left in the last notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=5899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "\n",
    "x_train,x_valid = normalize_to(x_train,x_valid)\n",
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "\n",
    "nh,bs = 50,512\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_view = view_tfm(1,28,28)\n",
    "cbfs = [Recorder,\n",
    "        partial(AvgStatsCallback,accuracy),\n",
    "        #CudaCallback,\n",
    "        partial(BatchTransformXCallback, mnist_view)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [8,16,32,64,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.912379609375, tensor(0.7047)]\n",
      "valid: [0.17211876220703126, tensor(0.9478)]\n",
      "train: [0.148779208984375, tensor(0.9526)]\n",
      "valid: [0.14120567626953126, tensor(0.9540)]\n",
      "CPU times: user 36 s, sys: 2.86 s, total: 38.9 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "# no batchnorm trains only with low lr\n",
    "\n",
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)\n",
    "%time run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1929393.27488, tensor(0.1155)]\n",
      "valid: [2.3021896484375, tensor(0.1064)]\n",
      "train: [2.3016140625, tensor(0.1136)]\n",
      "valid: [2.302555859375, tensor(0.1064)]\n",
      "CPU times: user 35.4 s, sys: 2.64 s, total: 38 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "# doesn't train with higher lr\n",
    "\n",
    "learn,run = get_learn_run(nfs, data, 1.0, conv_layer, cbs=cbfs)\n",
    "%time run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building our own `BatchNorm` layer from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=6018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # NB: pytorch bn mom is opposite of what you'd expect\n",
    "        self.mom,self.eps = mom,eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))   # gamma (scale parameter)\n",
    "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))   # beta  (shift parameter)\n",
    "        # learnable parameters help to maintain representational power of layer after normalization\n",
    "        \n",
    "        self.register_buffer('vars',  torch.ones(1,nf,1,1))\n",
    "        self.register_buffer('means', torch.zeros(1,nf,1,1))\n",
    "        # register_buffer: same as parameter (pushed to device, saved in state_dict)\n",
    "        #                  but not trained by optimizer (not returned in model.parameters())\n",
    "\n",
    "    def update_stats(self, x):\n",
    "        m = x.mean((0,2,3), keepdim=True) # mean averaged over batch and spatial dimensions => mean/channel\n",
    "        v = x.var ((0,2,3), keepdim=True) # keepdim=True => leaves empty unit axes and allows for broadcasting\n",
    "        self.means.lerp_(m, self.mom) # linearly interpolate previous means with current mean using momentum\n",
    "        self.vars.lerp_ (v, self.mom) # lerp : linear interpolation => x1*(1-momentum) + x2*(momentum) [pytorch]\n",
    "        # exponentially weighted moving average: influence of each previous point is exponentially decayed\n",
    "        return m,v\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            with torch.no_grad(): m,v = self.update_stats(x) # calculate mean/var and update running avg\n",
    "        else: m,v = self.means,self.vars  # inference: don't calculate mean/variance.  Use running avg instead\n",
    "        x = (x-m) / (v+self.eps).sqrt()   # normalize: subtract mean and divide by std (sqrt of var)\n",
    "        return x*self.mults + self.adds   # scale and shift normalized values w/ learnable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    # No bias needed if using bn\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(BatchNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_cnn_(m, f):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        f(m.weight, a=0.1)\n",
    "        if getattr(m, 'bias', None) is not None: m.bias.data.zero_()\n",
    "    for l in m.children(): init_cnn_(l, f)\n",
    "\n",
    "def init_cnn(m, uniform=False):\n",
    "    f = init.kaiming_uniform_ if uniform else init.kaiming_normal_\n",
    "    init_cnn_(m, f)\n",
    "\n",
    "def get_learn_run(nfs, data, lr, layer, cbs=None, opt_func=None, uniform=False, **kwargs):\n",
    "    model = get_cnn_model(data, nfs, layer, **kwargs)\n",
    "    init_cnn(model, uniform=uniform)\n",
    "    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use it in training and see how it helps keep the activations means to 0 and the std to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 1., conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(learn.model, append_stats) as hooks:\n",
    "    run.fit(1, learn)\n",
    "    fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "    for h in hooks[:-1]:\n",
    "        ms,ss = h.stats\n",
    "        ax0.plot(ms[:10])\n",
    "        ax1.plot(ss[:10])\n",
    "        h.remove()\n",
    "    plt.legend(range(6));\n",
    "    \n",
    "    fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "    for h in hooks[:-1]:\n",
    "        ms,ss = h.stats\n",
    "        ax0.plot(ms)\n",
    "        ax1.plot(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.27712578125, tensor(0.9130)]\n",
      "valid: [0.1102513916015625, tensor(0.9662)]\n",
      "train: [0.091840654296875, tensor(0.9715)]\n",
      "valid: [0.08538733520507813, tensor(0.9733)]\n",
      "CPU times: user 55.8 s, sys: 4.01 s, total: 59.8 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "# with batchnorm, training with higher lr and better accuracy\n",
    "\n",
    "learn,run = get_learn_run(nfs, data, 1.0, conv_layer, cbs=cbfs)\n",
    "%time run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builtin batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=6679)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf, eps=1e-5, momentum=0.1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.22017669921875, tensor(0.9305)]\n",
      "valid: [0.09249447631835937, tensor(0.9723)]\n",
      "train: [0.064310859375, tensor(0.9797)]\n",
      "valid: [0.07336126098632813, tensor(0.9789)]\n",
      "CPU times: user 49.5 s, sys: 3.53 s, total: 53 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "learn,run = get_learn_run(nfs, data, 1., conv_layer, cbs=cbfs)\n",
    "%time run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### With scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's add the usual warm-up/annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3, 0.7], [sched_lin(0.6, 2.), sched_lin(2., 0.1)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_layer, cbs=cbfs\n",
    "                          +[partial(ParamScheduler,'lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run.fit(8, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## More norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Layer norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From [the paper](https://arxiv.org/abs/1607.06450): \"*batch normalization cannot be applied to online learning tasks or to extremely large distributed models where the minibatches have to be small*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "General equation for a norm layer with learnable affine:\n",
    "\n",
    "$$y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "The difference with BatchNorm is\n",
    "1. we don't keep a moving average (the mean/variance of each img is independent)\n",
    "2. we don't average over the batches dimension but over the hidden dimension, so it's independent of the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=6717)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    __constants__ = ['eps']\n",
    "    def __init__(self, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.mult = nn.Parameter(tensor(1.))\n",
    "        self.add  = nn.Parameter(tensor(0.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        m = x.mean((1,2,3), keepdim=True) # mean averaged over channel and spatial dimensions => mean/image\n",
    "        v = x.var ((1,2,3), keepdim=True) \n",
    "        x = (x-m) / ((v+self.eps).sqrt()) # image brightness (mean) and contrast (variance) are normalized out...\n",
    "        return x*self.mult + self.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv_ln(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=True),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(LayerNorm())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.8, conv_ln, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Thought experiment*: can this distinguish foggy days from sunny days (assuming you're using it before the first conv)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Instance norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From [the paper](https://arxiv.org/abs/1607.08022): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The key difference between **contrast** and batch normalization is that the latter applies the normalization to a  whole batch of images instead for single ones:\n",
    "\n",
    "\\begin{equation}\\label{eq:bnorm}\n",
    "    y_{tijk} =  \\frac{x_{tijk} - \\mu_{i}}{\\sqrt{\\sigma_i^2 + \\epsilon}},\n",
    "    \\quad\n",
    "    \\mu_i = \\frac{1}{HWT}\\sum_{t=1}^T\\sum_{l=1}^W \\sum_{m=1}^H x_{tilm},\n",
    "    \\quad\n",
    "    \\sigma_i^2 = \\frac{1}{HWT}\\sum_{t=1}^T\\sum_{l=1}^W \\sum_{m=1}^H (x_{tilm} - mu_i)^2.\n",
    "\\end{equation}\n",
    "\n",
    "In order to combine the effects of instance-specific normalization and batch normalization, we propose to replace the latter by the *instance normalization* (also known as *contrast normalization*) layer:\n",
    "\n",
    "\\begin{equation}\\label{eq:inorm}\n",
    "    y_{tijk} =  \\frac{x_{tijk} - \\mu_{ti}}{\\sqrt{\\sigma_{ti}^2 + \\epsilon}},\n",
    "    \\quad\n",
    "    \\mu_{ti} = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H x_{tilm},\n",
    "    \\quad\n",
    "    \\sigma_{ti}^2 = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H (x_{tilm} - mu_{ti})^2.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    __constants__ = ['eps']\n",
    "    def __init__(self, nf, eps=1e-0):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        m = x.mean((2,3), keepdim=True) # mean over spatial dimensions => mean per image per channel\n",
    "        v = x.var ((2,3), keepdim=True)\n",
    "        res = (x-m) / ((v+self.eps).sqrt()) # removes differences in mean/var for each channel and image\n",
    "        return res*self.mults + self.adds   # useful for style transfer, not classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv_in(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=True),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(InstanceNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.1, conv_in, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Question*: why can't this classify anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lost in all those norms? The authors from the [group norm paper](https://arxiv.org/pdf/1803.08494.pdf) have you covered:\n",
    "\n",
    "![Various norms](images/norms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Group norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Intermediate generalization btw InstanceNorm and LayerNorm depending on # of groups\n",
    "- groups = 1         => InstanceNorm\n",
    "- groups = #channels => LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7213)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*From the PyTorch docs:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`GroupNorm(num_groups, num_channels, eps=1e-5, affine=True)`\n",
    "\n",
    "The input channels are separated into `num_groups` groups, each containing\n",
    "``num_channels / num_groups`` channels. The mean and standard-deviation are calculated\n",
    "separately over the each group. $\\gamma$ and $\\beta$ are learnable\n",
    "per-channel affine transform parameter vectorss of size `num_channels` if\n",
    "`affine` is ``True``.\n",
    "\n",
    "This layer uses statistics computed from input data in both training and\n",
    "evaluation modes.\n",
    "\n",
    "Args:\n",
    "-    num_groups (int): number of groups to separate the channels into\n",
    "-    num_channels (int): number of channels expected in input\n",
    "-    eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
    "-    affine: a boolean value that when set to ``True``, this module\n",
    "        has learnable per-channel affine parameters initialized to ones (for weights)\n",
    "        and zeros (for biases). Default: ``True``.\n",
    "\n",
    "Shape:\n",
    "- Input: `(N, num_channels, *)`\n",
    "- Output: `(N, num_channels, *)` (same shape as input)\n",
    "\n",
    "Examples::\n",
    "\n",
    "    >>> input = torch.randn(20, 6, 10, 10)\n",
    "    >>> # Separate 6 channels into 3 groups\n",
    "    >>> m = nn.GroupNorm(3, 6)\n",
    "    >>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "    >>> m = nn.GroupNorm(6, 6)\n",
    "    >>> # Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "    >>> m = nn.GroupNorm(1, 6)\n",
    "    >>> # Activating the module\n",
    "    >>> output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix small batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compute the statistics (mean and std) for a BatchNorm Layer on a small batch, it is possible that we get a standard deviation very close to 0. because there aren't many samples (the variance of one thing is 0. since it's equal to its mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, 2), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [164004.4032, tensor(0.1076)]\n",
      "valid: [724882507522952.4, tensor(0.1531)]\n",
      "CPU times: user 2min 53s, sys: 8.36 s, total: 3min 1s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "# learns very slowly with high lr: 1.0\n",
    "\n",
    "learn,run = get_learn_run(nfs, data, 1.0, conv_layer, cbs=cbfs)\n",
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [2.3629571875, tensor(0.1662)]\n",
      "valid: [1448330.5472, tensor(0.1841)]\n",
      "CPU times: user 2min 48s, sys: 7.81 s, total: 2min 56s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "# reducing learning rate doesn't improve accuracy\n",
    "\n",
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)\n",
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Batch Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem we introduce a Running BatchNorm that uses smoother running mean and variance for the mean and std."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RunningBatchNorm(nn.Module):\n",
    "#     def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "#         super().__init__()\n",
    "#         self.mom,self.eps = mom,eps\n",
    "#         self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "#         self.adds = nn.Parameter(torch.zeros(nf,1,1))\n",
    "#         self.register_buffer('sums', torch.zeros(1,nf,1,1))\n",
    "#         self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n",
    "#         self.register_buffer('batch', tensor(0.))\n",
    "#         self.register_buffer('count', tensor(0.))\n",
    "#         self.register_buffer('step', tensor(0.))\n",
    "#         self.register_buffer('dbias', tensor(0.))\n",
    "\n",
    "#     def update_stats(self, x):\n",
    "#         bs,nc,*_ = x.shape\n",
    "#         self.sums.detach_()\n",
    "#         self.sqrs.detach_()\n",
    "#         dims = (0,2,3)\n",
    "#         s = x.sum(dims, keepdim=True)\n",
    "#         ss = (x*x).sum(dims, keepdim=True)\n",
    "#         c = self.count.new_tensor(x.numel()/nc)\n",
    "#         mom1 = 1 - (1-self.mom)/math.sqrt(bs-1)\n",
    "#         self.mom1 = self.dbias.new_tensor(mom1)\n",
    "#         self.sums.lerp_(s, self.mom1)\n",
    "#         self.sqrs.lerp_(ss, self.mom1)\n",
    "#         self.count.lerp_(c, self.mom1)\n",
    "#         self.dbias = self.dbias*(1-self.mom1) + self.mom1\n",
    "#         self.batch += bs\n",
    "#         self.step += 1\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if self.training: self.update_stats(x)\n",
    "#         sums = self.sums\n",
    "#         sqrs = self.sqrs\n",
    "#         c = self.count\n",
    "#         if self.step<100:\n",
    "#             sums = sums / self.dbias\n",
    "#             sqrs = sqrs / self.dbias\n",
    "#             c    = c    / self.dbias\n",
    "#         means = sums/c\n",
    "#         vars = (sqrs/c).sub_(means*means)\n",
    "#         if bool(self.batch < 20): vars.clamp_min_(0.01)\n",
    "#         x = (x-means).div_((vars.add_(self.eps)).sqrt())\n",
    "#         return x.mul_(self.mults).add_(self.adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified version of above\n",
    "\n",
    "# key idea: use moving avg at training time as well as at inference time!!\n",
    "# exp weighted moving avg (lerp) of variance doesn't make sense\n",
    "# Variance => mean(x.pow(2)) - mean(x).pow(2)\n",
    "# lerp sums,squares,counts and then calculate variance from those\n",
    "\n",
    "class RunningBatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.register_buffer('sums', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('count', tensor(0.))\n",
    "        self.register_buffer('factor', tensor(0.))\n",
    "        self.register_buffer('offset', tensor(0.))\n",
    "        self.batch = 0\n",
    "        \n",
    "    def update_stats(self, x):\n",
    "        bs,nc,*_ = x.shape\n",
    "        self.sums.detach_()\n",
    "        self.sqrs.detach_()\n",
    "        s    = x.sum((0,2,3), keepdim=True)     # sum\n",
    "        ss   = (x*x).sum((0,2,3), keepdim=True) # sum of squares\n",
    "        c    = s.new_tensor(x.numel()/nc)       # count = batch size * spatial dimensions\n",
    "        mom1 = s.new_tensor(1 - (1-self.mom)/math.sqrt(bs-1))  # scale momentum by batchsize (new technique)\n",
    "        self.sums .lerp_(s , mom1)\n",
    "        self.sqrs .lerp_(ss, mom1)\n",
    "        self.count.lerp_(c , mom1) # exp weighted moving avg of count because bs could vary\n",
    "        self.batch += bs\n",
    "        means = self.sums/self.count\n",
    "        varns = (self.sqrs/self.count).sub_(means*means)\n",
    "        if bool(self.batch < 20): varns.clamp_min_(0.01)\n",
    "        self.factor = self.mults / (varns+self.eps).sqrt()\n",
    "        self.offset = self.adds - means*self.factor\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training: self.update_stats(x)\n",
    "        return x*self.factor + self.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_rbn(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(RunningBatchNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [nan, tensor(0.0985)]\n",
      "valid: [nan, tensor(0.0991)]\n",
      "CPU times: user 2min 49s, sys: 7.68 s, total: 2min 56s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "# doesn't learn with high learning rate\n",
    "\n",
    "learn,run = get_learn_run(nfs, data, 1.0, conv_rbn, cbs=cbfs)\n",
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.4000426953125, tensor(0.8957)]\n",
      "valid: [0.18907635498046876, tensor(0.9621)]\n",
      "CPU times: user 2min 50s, sys: 8.47 s, total: 2min 58s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "# with lower learning rate, accuracy is very good\n",
    "\n",
    "learn,run = get_learn_run(nfs, data, 0.4, conv_rbn, cbs=cbfs)\n",
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solves the small batch size issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we do in a single epoch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see with a decent batch size what result we can get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=8068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, 32), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_rbn, cbs=cbfs\n",
    "                          +[partial(ParamScheduler,'lr', sched_lin(1., 0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_auto_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
